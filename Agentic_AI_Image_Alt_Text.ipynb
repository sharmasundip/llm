{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17077726-5779-4eef-9e57-7c28c290b6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"Agentic_AI_Image_Alt_Text.ipynb\n",
    "\"\"\"\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f34a68-b29e-4e51-89ce-e8c783d7e0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary libraries\n",
    "!pip install crewai langchain-community ollama langchain pillow transformers torch\n",
    "\n",
    "import os\n",
    "from crewai import Agent, Task, Crew, Process\n",
    "from langchain_community.llms import Ollama\n",
    "from PIL import Image\n",
    "import io\n",
    "import base64\n",
    "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
    "\n",
    "# Ensure you have Ollama running with Llama3.2 model\n",
    "# You can pull llama3.2 with `ollama pull llama3:2`\n",
    "\n",
    "# Set up Ollama LLM\n",
    "ollama_llm = Ollama(model=\"llama3:2\")\n",
    "\n",
    "# Load BLIP model and processor\n",
    "processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-large\")\n",
    "model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-large\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae31e2b-0c71-4b46-9e59-d6dc9fded58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_image(image_path):\n",
    "    \"\"\"Describes an image using BLIP.\"\"\"\n",
    "    try:\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        inputs = processor(images=image, return_tensors=\"pt\")\n",
    "        outputs = model.generate(**inputs)\n",
    "        caption = processor.decode(outputs[0], skip_special_tokens=True)\n",
    "        return caption\n",
    "    except Exception as e:\n",
    "        return f\"Error describing image: {e}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2618e927-9eb4-438e-b244-69b86139ce71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agents\n",
    "image_analyzer = Agent(\n",
    "    role=\"Image Context Analyzer\",\n",
    "    goal=\"Analyze images and understand their context to generate accurate alternative text.\",\n",
    "    backstory=\"You are an expert in image recognition and understanding visual content.\",\n",
    "    llm=ollama_llm,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "alt_text_generator = Agent(\n",
    "    role=\"Alternative Text Generator\",\n",
    "    goal=\"Generate concise and descriptive alternative text for images based on their context.\",\n",
    "    backstory=\"You are a skilled writer with a focus on accessibility and clear communication.\",\n",
    "    llm=ollama_llm,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "review_agent = Agent(\n",
    "    role=\"Human Review Suggestion Agent\",\n",
    "    goal=\"When alt text is hard to generate, provide clear and concise suggestions for a human to review and complete.\",\n",
    "    backstory=\"You are an expert in knowing when a human is needed in the loop for complex tasks.\",\n",
    "    llm=ollama_llm,\n",
    "    verbose=True,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef8ba33-63af-4f10-9f7a-5b6abe4c96b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tasks\n",
    "analyze_image_task = Task(\n",
    "    description=\"Analyze the image and describe its main elements and context.\",\n",
    "    agent=image_analyzer,\n",
    ")\n",
    "\n",
    "generate_alt_text_task = Task(\n",
    "    description=\"Based on the image analysis, generate a concise and descriptive alternative text for the image. If the image is complex or you are unsure, provide a suggestion for human review.\",\n",
    "    agent=alt_text_generator,\n",
    ")\n",
    "\n",
    "review_task = Task(\n",
    "    description=\"If the Alt text generation agent is unable to create a good alt text, generate suggestions for a human to review and complete the alt text.\",\n",
    "    agent = review_agent,\n",
    "    context = [generate_alt_text_task],\n",
    ")\n",
    "\n",
    "# Crew\n",
    "crew = Crew(\n",
    "    agents=[image_analyzer, alt_text_generator, review_agent],\n",
    "    tasks=[analyze_image_task, generate_alt_text_task, review_task],\n",
    "    process=Process.sequential,  # You can also use Process.hierarchical\n",
    ")\n",
    "\n",
    "# Example usage (replace with actual image path)\n",
    "# Upload your image to Colab's file storage and change the path.\n",
    "image_path = \"your_image.jpg\" # Replace with the path to your uploaded image\n",
    "\n",
    "image_description = describe_image(image_path)\n",
    "\n",
    "# Simulate task execution\n",
    "analyze_image_task.context = image_description\n",
    "result = crew.kickoff()\n",
    "\n",
    "print(\"Result:\")\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
